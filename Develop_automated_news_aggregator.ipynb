{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project to automate api access \n",
    "+ I added my api key as config.py file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import config\n",
    "import math\n",
    "from newsapi import NewsApiClient\n",
    "import newspaper\n",
    "import requests\n",
    "from newspaper import fulltext\n",
    "\n",
    "# Hit Api with credentials\n",
    "newsapi = NewsApiClient(api_key=config.api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab all sources\n",
    "+ read through available sources list and make df storing domain and source name\n",
    "+ I hit a ton of sources below, we can clearly narrow it down \n",
    "+ I do this so I can join these things together as string in next block to insert into our query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        domains                      sources\n",
      "0                        https://abcnews.go.com                     abc-news\n",
      "1                    http://www.abc.net.au/news                  abc-news-au\n",
      "2                    https://www.aftenposten.no                  aftenposten\n",
      "3                      http://www.aljazeera.com           al-jazeera-english\n",
      "4                            http://www.ansa.it                         ansa\n",
      "5                         http://www.argaam.com                       argaam\n",
      "6                        http://arstechnica.com                 ars-technica\n",
      "7                        https://arynews.tv/ud/                     ary-news\n",
      "8                           https://apnews.com/             associated-press\n",
      "9                            http://www.afr.com  australian-financial-review\n",
      "10                        https://www.axios.com                        axios\n",
      "11                    http://www.bbc.co.uk/news                     bbc-news\n",
      "12                   http://www.bbc.co.uk/sport                    bbc-sport\n",
      "13                           http://www.bild.de                         bild\n",
      "14                   http://br.blastingnews.com             blasting-news-br\n",
      "15                http://www.bleacherreport.com              bleacher-report\n",
      "16                     http://www.bloomberg.com                    bloomberg\n",
      "17                     http://www.breitbart.com               breitbart-news\n",
      "18               http://www.businessinsider.com             business-insider\n",
      "19                http://uk.businessinsider.com          business-insider-uk\n",
      "20                     https://www.buzzfeed.com                     buzzfeed\n",
      "21                       http://www.cbc.ca/news                     cbc-news\n",
      "22                       http://www.cbsnews.com                     cbs-news\n",
      "23                          http://www.cnbc.com                         cnbc\n",
      "24                            http://us.cnn.com                          cnn\n",
      "25                   http://cnnespanol.cnn.com/                       cnn-es\n",
      "26                          https://www.ccn.com            crypto-coins-news\n",
      "27   http://www.dailymail.co.uk/home/index.html                   daily-mail\n",
      "28                   http://www.tagesspiegel.de             der-tagesspiegel\n",
      "29                     http://www.zeit.de/index                     die-zeit\n",
      "..                                          ...                          ...\n",
      "104                               http://t3n.de                          t3n\n",
      "105                        http://talksport.com                    talksport\n",
      "106                      https://techcrunch.com                   techcrunch\n",
      "107                       https://techcrunch.cn                techcrunch-cn\n",
      "108                    http://www.techradar.com                    techradar\n",
      "109     http://www.theamericanconservative.com/    the-american-conservative\n",
      "110             https://www.theglobeandmail.com           the-globe-and-mail\n",
      "111                          http://thehill.com                     the-hill\n",
      "112                     http://www.thehindu.com                    the-hindu\n",
      "113               http://www.huffingtonpost.com          the-huffington-post\n",
      "114                  https://www.irishtimes.com              the-irish-times\n",
      "115                      https://www.jpost.com/           the-jerusalem-post\n",
      "116                  http://www.theladbible.com                the-lad-bible\n",
      "117                      http://www.nytimes.com           the-new-york-times\n",
      "118                       http://thenextweb.com                 the-next-web\n",
      "119                http://www.thesportbible.com              the-sport-bible\n",
      "120                  http://www.telegraph.co.uk                the-telegraph\n",
      "121          http://timesofindia.indiatimes.com           the-times-of-india\n",
      "122                     http://www.theverge.com                    the-verge\n",
      "123                          http://www.wsj.com      the-wall-street-journal\n",
      "124              https://www.washingtonpost.com          the-washington-post\n",
      "125            https://www.washingtontimes.com/         the-washington-times\n",
      "126                             http://time.com                         time\n",
      "127                http://www.usatoday.com/news                    usa-today\n",
      "128                       https://news.vice.com                    vice-news\n",
      "129                       https://www.wired.com                        wired\n",
      "130                        https://www.wired.de                     wired-de\n",
      "131                          http://www.wiwo.de            wirtschafts-woche\n",
      "132                       http://xinhuanet.com/                   xinhua-net\n",
      "133                       http://www.ynet.co.il                         ynet\n",
      "\n",
      "[134 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "sources = newsapi.get_sources()\n",
    "new_orgs = sources[\"sources\"]\n",
    "my_sources = {}\n",
    "for i, x in enumerate(new_orgs):\n",
    "    my_sources[i] = (x['id'])\n",
    "domains = sources[\"sources\"]\n",
    "my_domains = {}\n",
    "for i, x in enumerate(domains):\n",
    "    my_domains[i] = (x['url'])\n",
    "sources = pd.Series(my_sources).to_frame(\"sources\")\n",
    "domains = pd.Series(my_domains).to_frame(\"domains\")\n",
    "query_keys_df = domains.join(sources)\n",
    "print(query_keys_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing data sources\n",
    "+ Lets attempt to grab some sources from different geographic locations as well as different idological perspectives\n",
    "\n",
    "+ categorizing news sources\n",
    "    + Traditional TV MSM\n",
    "        +  http://us.cnn.com   \n",
    "        +  http://www.cnbc.com \n",
    "        +  http://www.foxnews.com  \n",
    "        +  http://www.msnbc.com  \n",
    "        +  https://abcnews.go.com  \n",
    "        +  http://www.nbcnews.com  \n",
    "    + Traditional publications \n",
    "        +  http://www.nytimes.com  \n",
    "        +  https://www.washingtonpost.com \n",
    "        \n",
    "    + Internet Sources\n",
    "        +  http://www.huffingtonpost.com \n",
    "        +  https://www.politico.com\n",
    "        +  http://www.breitbart.com \n",
    "        +  https://news.google.com \n",
    "        +  https://www.buzzfeed.com \n",
    "        +  https://news.vice.com  \n",
    "    + Financial publications\n",
    "        +  http://www.economist.com\n",
    "        +  http://www.bloomberg.com \n",
    "        +  http://www.businessinsider.com \n",
    "        +  http://www.wsj.com\n",
    "        +  http://fortune.com  \n",
    "        \n",
    "    + News aggregators\n",
    "        +  https://apnews.com/ \n",
    "        +  http://www.reuters.com \n",
    "    + foreign reporting\n",
    "         + http://www.aljazeera.com  \n",
    "         + http://www.bbc.co.uk/news   \n",
    "         + https://www.jpost.com/  \n",
    "         + http://timesofindia.indiatimes.com \n",
    "         + https://russian.rt.com \n",
    "         + https://www.theguardian.com/uk \n",
    "         + http://www.independent.co.uk  \n",
    "         + http://www.telegraph.co.uk  \n",
    "\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc-news,al-jazeera-english,associated-press,bbc-news,bloomberg,breitbart-news,business-insider,buzzfeed,cbs-news,cnbc,cnn,four-four-two,fox-sports,google-news-ar,infobae,nbc-news,news24,polygon,rt,rte,the-hill,the-irish-times,the-new-york-times,the-sport-bible,the-times-of-india,the-washington-post,usa-today,vice-news,xinhua-net'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## Literally picking data sources from df i printed above \n",
    "a= query_keys_df.iloc[[0,3,8,11,16,17,18,20,22,23,24,39,41,44,62,82,83,93,98,99,111,114,117,119,121,124,127,128,132],[1]]\n",
    "list_sources =a[\"sources\"].tolist()\n",
    "\n",
    "## build out string for query request \n",
    "myString = \",\".join(list_sources)\n",
    "myString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ You can see the string which we will insert into sources above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets begin process of automating query calls\n",
    "+ After the first call we can see our total results for the day, which will allow us to make subsequent calls.\n",
    "+ first lets build function to clean query returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_query(query):\n",
    "    for x in query['articles']:\n",
    "        try:\n",
    "            x[\"source\"] = x[\"source\"][\"name\"]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            x['publishedAt'] = str.split(x['publishedAt'], \"T\")[0]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            del x['urlToImage']\n",
    "        except KeyError:\n",
    "            pass\n",
    "    my_df = pd.DataFrame(query[\"articles\"])\n",
    "    return my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to hit the api\n",
    "+ Originally I had a loop here.  instead I figured I would just build a function that takes start data, end data, query term(candidate)\n",
    "    + The original code kept giving me a query limit reached result, so I decided to change up strategy and search one day at a time\n",
    "    + after we hit the papers at the start for past 30 days, we will only need 1 day at a time going forward.\n",
    "    + I built in some print statements for error handeling, which you will see below in the block after this, the behavior gets strange at a point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "candidates_list=[]\n",
    "\n",
    "# Make first call\n",
    "def hit_api(start,end,q,myString):\n",
    "    ## catch bug with formatted strings for dates\n",
    "    if end < 10:\n",
    "        start_str = \"0\"+ str(start)\n",
    "        end_str = \"0\"+ str(end)\n",
    "    elif end==10:\n",
    "        start_str = \"0\"+ str(start)\n",
    "        end_str = str(end)\n",
    "    else :\n",
    "        start_str = str(start)\n",
    "        end_str = str(end)\n",
    "    print(start_str)\n",
    "    print(end_str)    \n",
    "    all_articles = newsapi.get_everything(q=q,\n",
    "                                          sources=myString,\n",
    "                                          domains='https://apnews.com/,http://www.nytimes.com',\n",
    "                                          language='en',\n",
    "                                          from_param='2019-09-{}'.format(start_str),\n",
    "                                          to='2019-09-{}'.format(end_str),\n",
    "                                          sort_by='relevancy',\n",
    "                                          page_size=100,\n",
    "                                          page=1)\n",
    "    total_pages = math.ceil(all_articles[\"totalResults\"]/100)\n",
    "    print(\"query will return: \"+ str(all_articles[\"totalResults\"]))\n",
    "    all_articles = clean_query(all_articles)\n",
    "    candidates_list.append(all_articles)\n",
    "    return(candidates_list)\n",
    "\n",
    "\n",
    "\n",
    "### original code\n",
    "#     start=1\n",
    "#     end=5\n",
    "#     for page in range(2,total_pages+1):\n",
    "#         start_str = \"0\"+ str(start)\n",
    "#         end_str = \"0\"+ str(end)\n",
    "#         all_articles = newsapi.get_everything(q='Bernie Sanders',\n",
    "#                                           sources=myString,\n",
    "#                                           domains='https://apnews.com/,http://www.nytimes.com',\n",
    "#                                           language='en',\n",
    "#                                           from_param='2019-{}-09'.format(start_str),\n",
    "#                                           to='2019-{}-09'.format(end_str),\n",
    "#                                           sort_by='relevancy',\n",
    "#                                           page_size=100,\n",
    "#                                           page=page)\n",
    "#         print(page)\n",
    "#         ran_query = clean_query(all_articles)\n",
    "#         #ran_query_df = pd.DataFrame(ran_query['articles'])\n",
    "#         bernie_sanders_list.append(ran_query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built out a loop \n",
    "+ simple, look at first day of september to last day incrementing start and end by 1 each time\n",
    "+ YOu can see from the prints that something seems to be going wrong when we hit day 10, I dont get why.  We are getting data for that day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "02\n",
      "query will return: 31\n",
      "02\n",
      "03\n",
      "query will return: 48\n",
      "03\n",
      "04\n",
      "query will return: 76\n",
      "04\n",
      "05\n",
      "query will return: 94\n",
      "05\n",
      "06\n",
      "query will return: 84\n",
      "06\n",
      "07\n",
      "query will return: 56\n",
      "07\n",
      "08\n",
      "query will return: 47\n",
      "08\n",
      "09\n",
      "query will return: 60\n",
      "09\n",
      "10\n",
      "query will return: 81\n",
      "10\n",
      "11\n",
      "query will return: 116\n",
      "11\n",
      "12\n",
      "query will return: 151\n",
      "12\n",
      "13\n",
      "query will return: 268\n",
      "13\n",
      "14\n",
      "query will return: 213\n",
      "14\n",
      "15\n",
      "query will return: 64\n",
      "15\n",
      "16\n",
      "query will return: 83\n",
      "16\n",
      "17\n",
      "query will return: 106\n",
      "17\n",
      "18\n",
      "query will return: 127\n",
      "18\n",
      "19\n",
      "query will return: 152\n",
      "19\n",
      "20\n",
      "query will return: 136\n",
      "20\n",
      "21\n",
      "query will return: 86\n",
      "21\n",
      "22\n",
      "query will return: 68\n",
      "22\n",
      "23\n",
      "query will return: 76\n",
      "23\n",
      "24\n",
      "query will return: 103\n",
      "24\n",
      "25\n",
      "query will return: 95\n",
      "25\n",
      "26\n",
      "query will return: 65\n",
      "26\n",
      "27\n",
      "query will return: 57\n",
      "27\n",
      "28\n",
      "query will return: 36\n",
      "28\n",
      "29\n",
      "query will return: 29\n",
      "29\n",
      "30\n",
      "query will return: 44\n",
      "30\n",
      "31\n",
      "query will return: 25\n"
     ]
    }
   ],
   "source": [
    "for x in range(1,31):\n",
    "    df=hit_api(x,x+1,'Bernie|Sanders',myString)\n",
    "Bernie_df = pd.concat(df)\n",
    "Bernie_df= Bernie_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we should expect: 2203 articles\n",
      "we have 1168 unique links\n"
     ]
    }
   ],
   "source": [
    "Bernie_df.shape\n",
    "print(\"we should expect: {} articles\".format(Bernie_df.shape[0]))\n",
    "unique_array = Bernie_df.url.unique()\n",
    "print(\"we have {} unique links\".format(unique_array.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have 1032 rows that share some sort of identical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1035, 7)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicateRowsDF = Bernie_df[Bernie_df.duplicated(\"url\")]\n",
    "duplicateRowsDF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>description</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Welcome to Majority.FM 's AM QUICKIE! Brought ...</td>\n",
       "      <td>2019-09-24</td>\n",
       "      <td>Google News</td>\n",
       "      <td>AM QUICKIE: September 24th, 2019 w/ Lucie Stei...</td>\n",
       "      <td>http://feedproxy.google.com/~r/MajorityReport/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Welcome to Majority.FM 's AM QUICKIE! Brought ...</td>\n",
       "      <td>2019-09-11</td>\n",
       "      <td>Google News</td>\n",
       "      <td>AM QUICKIE: September 11th, 2019 w/ Lucie Stei...</td>\n",
       "      <td>http://feedproxy.google.com/~r/MajorityReport/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Welcome to Majority.FM 's AM QUICKIE! Brought ...</td>\n",
       "      <td>2019-09-18</td>\n",
       "      <td>Google News</td>\n",
       "      <td>AM QUICKIE: September 18th, 2019 w/ Lucie Stei...</td>\n",
       "      <td>http://feedproxy.google.com/~r/MajorityReport/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Welcome to Majority.FM 's AM QUICKIE! Brought ...</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>Google News</td>\n",
       "      <td>AM QUICKIE: September 20th, 2019 w/ Sam Seder ...</td>\n",
       "      <td>http://feedproxy.google.com/~r/MajorityReport/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Welcome to Majority.FM 's AM QUICKIE! Brought ...</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>Google News</td>\n",
       "      <td>AM QUICKIE: September 20th, 2019 w/ Sam Seder ...</td>\n",
       "      <td>http://feedproxy.google.com/~r/MajorityReport/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Welcome to Majority.FM 's AM QUICKIE! Brought ...</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>Google News</td>\n",
       "      <td>AM QUICKIE: September 17th, 2019 w/ Lucie Stei...</td>\n",
       "      <td>http://feedproxy.google.com/~r/MajorityReport/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Welcome to Majority.FM 's AM QUICKIE! Brought ...</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>Google News</td>\n",
       "      <td>AM QUICKIE: September 17th, 2019 w/ Lucie Stei...</td>\n",
       "      <td>http://feedproxy.google.com/~r/MajorityReport/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Tom Woods, Tom Woods</td>\n",
       "      <td>None</td>\n",
       "      <td>Bernie Sanders is proposing a nationwide progr...</td>\n",
       "      <td>2019-09-24</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Ep. 1498 Against Bernie's National Rent Control</td>\n",
       "      <td>http://feedproxy.google.com/~r/TheTomWoodsShow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Tom Woods, Tom Woods</td>\n",
       "      <td>None</td>\n",
       "      <td>Bernie Sanders is proposing a nationwide progr...</td>\n",
       "      <td>2019-09-24</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Ep. 1498 Against Bernie's National Rent Control</td>\n",
       "      <td>http://feedproxy.google.com/~r/TheTomWoodsShow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Tom Woods, Tom Woods</td>\n",
       "      <td>None</td>\n",
       "      <td>Bernie Sanders is proposing a nationwide progr...</td>\n",
       "      <td>2019-09-24</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Ep. 1498 Against Bernie's National Rent Control</td>\n",
       "      <td>http://feedproxy.google.com/~r/TheTomWoodsShow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Carmen Reinicke</td>\n",
       "      <td>None</td>\n",
       "      <td>The US Chamber of Commerce's Center for Capita...</td>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>Google News</td>\n",
       "      <td>The US Chamber of Commerce released a report s...</td>\n",
       "      <td>http://feedproxy.google.com/~r/businessinsider...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Carmen Reinicke</td>\n",
       "      <td>None</td>\n",
       "      <td>The US Chamber of Commerce's Center for Capita...</td>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>Google News</td>\n",
       "      <td>The US Chamber of Commerce released a report s...</td>\n",
       "      <td>http://feedproxy.google.com/~r/businessinsider...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Carmen Reinicke</td>\n",
       "      <td>None</td>\n",
       "      <td>Senator Bernie Sanders on Monday announced a n...</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Bernie Sanders unveils 'inequality tax' target...</td>\n",
       "      <td>http://feedproxy.google.com/~r/businessinsider...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Carmen Reinicke</td>\n",
       "      <td>None</td>\n",
       "      <td>Senator Bernie Sanders on Monday announced a n...</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Bernie Sanders unveils 'inequality tax' target...</td>\n",
       "      <td>http://feedproxy.google.com/~r/businessinsider...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feedback@businessinsider.com (Carmen Reinicke)...</td>\n",
       "      <td>None</td>\n",
       "      <td>Getty Images / Scott Eisen Senator Bernie Sand...</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Bernie Sanders unveils 'inequality tax' target...</td>\n",
       "      <td>http://feedproxy.google.com/~r/businessinsider...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feedback@businessinsider.com (Carmen Reinicke)...</td>\n",
       "      <td>None</td>\n",
       "      <td>Getty Images / Scott Eisen Senator Bernie Sand...</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Bernie Sanders unveils 'inequality tax' target...</td>\n",
       "      <td>http://feedproxy.google.com/~r/businessinsider...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>We’ve gone from drought to flood. People who c...</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Does Climate Make Good Political TV?</td>\n",
       "      <td>http://feedproxy.google.com/~r/greentechmedia/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>We’ve gone from drought to flood. People who c...</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Does Climate Make Good Political TV?</td>\n",
       "      <td>http://feedproxy.google.com/~r/greentechmedia/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Annie Linskey, Amy B Wang and Cleve Wootson Jr...</td>\n",
       "      <td>NEW YORK - Sen. Elizabeth Warren hailed the po...</td>\n",
       "      <td>NEW YORK - Sen. Elizabeth Warren hailed the po...</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>The Washington Post</td>\n",
       "      <td>Warren, before huge NYC crowd, touts herself a...</td>\n",
       "      <td>http://www.washingtonpost.com/politics/2019/09...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               author  \\\n",
       "68                                               None   \n",
       "82                                               None   \n",
       "87                                               None   \n",
       "50                                               None   \n",
       "77                                               None   \n",
       "95                                               None   \n",
       "76                                               None   \n",
       "28                               Tom Woods, Tom Woods   \n",
       "58                               Tom Woods, Tom Woods   \n",
       "52                               Tom Woods, Tom Woods   \n",
       "30                                    Carmen Reinicke   \n",
       "43                                    Carmen Reinicke   \n",
       "15                                    Carmen Reinicke   \n",
       "25                                    Carmen Reinicke   \n",
       "0   feedback@businessinsider.com (Carmen Reinicke)...   \n",
       "0   feedback@businessinsider.com (Carmen Reinicke)...   \n",
       "49                                               None   \n",
       "35                                               None   \n",
       "23  Annie Linskey, Amy B Wang and Cleve Wootson Jr...   \n",
       "\n",
       "                                              content  \\\n",
       "68                                               None   \n",
       "82                                               None   \n",
       "87                                               None   \n",
       "50                                               None   \n",
       "77                                               None   \n",
       "95                                               None   \n",
       "76                                               None   \n",
       "28                                               None   \n",
       "58                                               None   \n",
       "52                                               None   \n",
       "30                                               None   \n",
       "43                                               None   \n",
       "15                                               None   \n",
       "25                                               None   \n",
       "0                                                None   \n",
       "0                                                None   \n",
       "49                                               None   \n",
       "35                                               None   \n",
       "23  NEW YORK - Sen. Elizabeth Warren hailed the po...   \n",
       "\n",
       "                                          description publishedAt  \\\n",
       "68  Welcome to Majority.FM 's AM QUICKIE! Brought ...  2019-09-24   \n",
       "82  Welcome to Majority.FM 's AM QUICKIE! Brought ...  2019-09-11   \n",
       "87  Welcome to Majority.FM 's AM QUICKIE! Brought ...  2019-09-18   \n",
       "50  Welcome to Majority.FM 's AM QUICKIE! Brought ...  2019-09-20   \n",
       "77  Welcome to Majority.FM 's AM QUICKIE! Brought ...  2019-09-20   \n",
       "95  Welcome to Majority.FM 's AM QUICKIE! Brought ...  2019-09-17   \n",
       "76  Welcome to Majority.FM 's AM QUICKIE! Brought ...  2019-09-17   \n",
       "28  Bernie Sanders is proposing a nationwide progr...  2019-09-24   \n",
       "58  Bernie Sanders is proposing a nationwide progr...  2019-09-24   \n",
       "52  Bernie Sanders is proposing a nationwide progr...  2019-09-24   \n",
       "30  The US Chamber of Commerce's Center for Capita...  2019-09-21   \n",
       "43  The US Chamber of Commerce's Center for Capita...  2019-09-21   \n",
       "15  Senator Bernie Sanders on Monday announced a n...  2019-09-30   \n",
       "25  Senator Bernie Sanders on Monday announced a n...  2019-09-30   \n",
       "0   Getty Images / Scott Eisen Senator Bernie Sand...  2019-09-30   \n",
       "0   Getty Images / Scott Eisen Senator Bernie Sand...  2019-09-30   \n",
       "49  We’ve gone from drought to flood. People who c...  2019-09-17   \n",
       "35  We’ve gone from drought to flood. People who c...  2019-09-17   \n",
       "23  NEW YORK - Sen. Elizabeth Warren hailed the po...  2019-09-17   \n",
       "\n",
       "                 source                                              title  \\\n",
       "68          Google News  AM QUICKIE: September 24th, 2019 w/ Lucie Stei...   \n",
       "82          Google News  AM QUICKIE: September 11th, 2019 w/ Lucie Stei...   \n",
       "87          Google News  AM QUICKIE: September 18th, 2019 w/ Lucie Stei...   \n",
       "50          Google News  AM QUICKIE: September 20th, 2019 w/ Sam Seder ...   \n",
       "77          Google News  AM QUICKIE: September 20th, 2019 w/ Sam Seder ...   \n",
       "95          Google News  AM QUICKIE: September 17th, 2019 w/ Lucie Stei...   \n",
       "76          Google News  AM QUICKIE: September 17th, 2019 w/ Lucie Stei...   \n",
       "28          Google News    Ep. 1498 Against Bernie's National Rent Control   \n",
       "58          Google News    Ep. 1498 Against Bernie's National Rent Control   \n",
       "52          Google News    Ep. 1498 Against Bernie's National Rent Control   \n",
       "30          Google News  The US Chamber of Commerce released a report s...   \n",
       "43          Google News  The US Chamber of Commerce released a report s...   \n",
       "15          Google News  Bernie Sanders unveils 'inequality tax' target...   \n",
       "25          Google News  Bernie Sanders unveils 'inequality tax' target...   \n",
       "0           Google News  Bernie Sanders unveils 'inequality tax' target...   \n",
       "0           Google News  Bernie Sanders unveils 'inequality tax' target...   \n",
       "49          Google News               Does Climate Make Good Political TV?   \n",
       "35          Google News               Does Climate Make Good Political TV?   \n",
       "23  The Washington Post  Warren, before huge NYC crowd, touts herself a...   \n",
       "\n",
       "                                                  url  \n",
       "68  http://feedproxy.google.com/~r/MajorityReport/...  \n",
       "82  http://feedproxy.google.com/~r/MajorityReport/...  \n",
       "87  http://feedproxy.google.com/~r/MajorityReport/...  \n",
       "50  http://feedproxy.google.com/~r/MajorityReport/...  \n",
       "77  http://feedproxy.google.com/~r/MajorityReport/...  \n",
       "95  http://feedproxy.google.com/~r/MajorityReport/...  \n",
       "76  http://feedproxy.google.com/~r/MajorityReport/...  \n",
       "28  http://feedproxy.google.com/~r/TheTomWoodsShow...  \n",
       "58  http://feedproxy.google.com/~r/TheTomWoodsShow...  \n",
       "52  http://feedproxy.google.com/~r/TheTomWoodsShow...  \n",
       "30  http://feedproxy.google.com/~r/businessinsider...  \n",
       "43  http://feedproxy.google.com/~r/businessinsider...  \n",
       "15  http://feedproxy.google.com/~r/businessinsider...  \n",
       "25  http://feedproxy.google.com/~r/businessinsider...  \n",
       "0   http://feedproxy.google.com/~r/businessinsider...  \n",
       "0   http://feedproxy.google.com/~r/businessinsider...  \n",
       "49  http://feedproxy.google.com/~r/greentechmedia/...  \n",
       "35  http://feedproxy.google.com/~r/greentechmedia/...  \n",
       "23  http://www.washingtonpost.com/politics/2019/09...  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bernie_df.sort_values(by=['url'])[1:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hitting newspaper 3k Api with links\n",
    "+ We can deal with duplicates and streamlining the above later\n",
    "+ to demonstrate a working product I feed our url into newspaper 3k \n",
    "+ Id say it takes 5-10 seconds per article to fetch complete text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_full_text=[]\n",
    "for link in Bernie_df['url'][0:10]:\n",
    "    html = requests.get(link).text\n",
    "    text = fulltext(html)\n",
    "    list_full_text.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Union bosses, closely tied to the Democrat Party, say American union workers sticking with President Trump in 2020 and his economic nationalist agenda is “a serious problem” for them.\\n\\nA report by the Wall Street Journal reveals how union bosses and Democrats are looking to peel off Trump’s support from American union workers who back his agenda, where most recently he has demanded multinational corporations move their production in China to the U.S.\\n\\nThe Journal reports:\\n\\n“It’s a serious problem for us,” said Alan Netland, president of the North East Area Labor Council in Duluth, Minn., which represents 40,000 union members. “People may say, ‘I voted Republican and the world didn’t fall in, so maybe I better keep doing that.’” [Emphasis added] Union officials, along with Democratic presidential candidates, are now trying to highlight what they see as a yawning gap between the president’s pro-worker rhetoric and his policies. [Emphasis added] … Democratic candidates have put appeals to working-class voters at the front of their campaigns. “I am a union man,” declared former Vice President Joe Biden, who leads in 2020 primary polls, during his campaign kickoff in Pennsylvania in May. [Emphasis added]\\n\\nVice President of the United Mine Workers of America in Uniontown, Pennsylvania, Chuck Knissel said based on the current 2020 Democrats running for president, it will be difficult to get union workers to vote for anyone other than Trump.\\n\\n“It’s going to be tough to get our members to vote for a Democrat,” Knissel told the Journal.\\n\\nIn interviews with the Journal, union workers who supported Trump in 2016 said 2020 Democrats have “gone so far left” with positions such as forcing union workers off their current healthcare plans and onto Medicare, as well as their calls to eliminate the coal industry entirely and provide free taxpayer-funded healthcare to illegal aliens.\\n\\nSome Democrat candidates, such as Sen. Bernie Sanders (I-VT), have been forced to shift their healthcare policy plans after union workers voiced opposition to the Medicare for All plan. Others, such as Sen. Elizabeth Warren (D-MA), have attempted to supplement their 2020 platforms with plans such as cracking down on corporations outsourcing American jobs — the agenda that Trump heralded in 2016.\\n\\nJohn Binder is a reporter for Breitbart News. Follow him on Twitter at @JxhnBinder.'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_full_text[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "+ we need to functionize streamline and clean up query calls.\n",
    "+ sorry my python is rusty."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
