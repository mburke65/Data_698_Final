{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things you need\n",
    "+ config file with api key\n",
    "+ Your user agent info can get https://www.whatismybrowser.com/detect/what-is-my-user-agent and replace the headers variable with your info\n",
    "    + header variable is line 10 in both scraping block\n",
    "+ Script splits up your sources into 2 queries and saves them as csv files.  I created a csv folder for them\n",
    "\n",
    "## change query\n",
    "Hit other candidates as well and make sure that the range (20,31) is no more than 30 days ago.  If you get a out of range error just change 20 to whatever day of month it is, or day of month +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import config\n",
    "import math\n",
    "import csv\n",
    "import sys\n",
    "from newsapi import NewsApiClient\n",
    "import newspaper\n",
    "import requests\n",
    "from newspaper import fulltext\n",
    "import time\n",
    "# Hit Api with credentials\n",
    "newsapi = NewsApiClient(api_key=config.api_key)\n",
    "\n",
    "\n",
    "## global variables\n",
    "candidates_list = []\n",
    "total_count = []\n",
    "\n",
    "\n",
    "def error_checks():\n",
    "    ##validate that df shape[0] is equal to expected query count\n",
    "    print(\"we should expect: {} articles\".format(sum(total_count)))\n",
    "    print(\"we have: {} articles\".format(Cand_df.shape[0]))\n",
    "\n",
    "\n",
    "    ## test 100 results theory\n",
    "    over_100 = sum([x-100 for x in total_count if x>100 ])\n",
    "    print(\"{} results came into query that exceeded 100 hits in a day.\".format(over_100))\n",
    "\n",
    "\n",
    "    ##unique links\n",
    "    unique_array = Cand_df.url.unique()\n",
    "    print(\"we have {} unique links\".format(unique_array.shape[0]))\n",
    "    \n",
    "    duplicateRowsDF = Cand_df[Cand_df.duplicated(\"url\")]\n",
    "    print(\"we have duplciate shape df of: {} \".format(duplicateRowsDF.shape))\n",
    "\n",
    "def clean_query(query):\n",
    "    for x in query['articles']:\n",
    "        try:\n",
    "            x[\"source\"] = x[\"source\"][\"name\"]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            x['publishedAt'] = str.split(x['publishedAt'], \"T\")[0]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            del x['urlToImage']\n",
    "        except KeyError:\n",
    "            pass\n",
    "    my_df = pd.DataFrame(query[\"articles\"])\n",
    "    return my_df\n",
    "\n",
    "def hit_api(start, end, q, myString2):\n",
    "\n",
    "    # catch bug with formatted strings for dates\n",
    "    if end < 10:\n",
    "        start_str = \"0\" + str(start)\n",
    "        end_str = \"0\" + str(end)\n",
    "    elif end == 10:\n",
    "        start_str = \"0\" + str(start)\n",
    "        end_str = str(end)\n",
    "    else:\n",
    "        start_str = str(start)\n",
    "        end_str = str(end)\n",
    "\n",
    "    # API query\n",
    "    all_articles = newsapi.get_everything(q=q,\n",
    "                                          sources=myString2,\n",
    "                                          language='en',\n",
    "                                          from_param='2019-09-{}'.format(\n",
    "                                              start_str),\n",
    "                                          to='2019-09-{}'.format(end_str),\n",
    "                                          sort_by='relevancy',\n",
    "                                          page_size=100,\n",
    "                                          page=1)\n",
    "\n",
    "    # get count\n",
    "    total_pages = math.ceil(all_articles[\"totalResults\"]/100)\n",
    "    print(\"query will return: \" + str(all_articles[\"totalResults\"]))\n",
    "\n",
    "    # store count to check versus dimension of df later\n",
    "    total_count.append(all_articles[\"totalResults\"])\n",
    "\n",
    "    # Clen query\n",
    "    all_articles = clean_query(all_articles)\n",
    "\n",
    "    # append to list\n",
    "    candidates_list.append(all_articles)\n",
    "    return(candidates_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## import data dictionary form github\n",
    "url = 'https://raw.githubusercontent.com/mburke65/Data_698_Final/master/lists.csv'\n",
    "df = pd.read_csv(url, error_bad_lines=False)\n",
    "\n",
    "# picking data sources from file on github\n",
    "a= df.iloc[[16,17,24],:]\n",
    "b= df.iloc[[40,43,77],:]\n",
    "list_sources = a[\"sources\"].tolist()\n",
    "\n",
    "# build out string for query request\n",
    "myString = \",\".join(list_sources)\n",
    "\n",
    "list_sources2 = b[\"sources\"].tolist()\n",
    "myString2 = \",\".join(list_sources2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Wall street journal and NYT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query will return: 21\n",
      "query will return: 30\n",
      "query will return: 25\n",
      "query will return: 19\n",
      "query will return: 21\n",
      "query will return: 14\n",
      "query will return: 5\n",
      "query will return: 17\n",
      "query will return: 324\n",
      "we should expect: 476 articles\n",
      "we have: 252 articles\n",
      "224 results came into query that exceeded 100 hits in a day.\n",
      "we have 179 unique links\n",
      "we have duplciate shape df of: (73, 7) \n",
      "251\n",
      "250\n",
      "249\n",
      "248\n",
      "no words found\n",
      "247\n",
      "246\n",
      "245\n",
      "244\n",
      "243\n",
      "242\n",
      "241\n",
      "no words found\n",
      "240\n",
      "239\n",
      "238\n",
      "237\n",
      "236\n",
      "235\n",
      "234\n",
      "233\n",
      "232\n",
      "231\n",
      "230\n",
      "229\n",
      "228\n",
      "227\n",
      "226\n",
      "225\n",
      "no words found\n",
      "224\n",
      "223\n",
      "222\n",
      "221\n",
      "220\n",
      "no words found\n",
      "219\n",
      "218\n",
      "217\n",
      "216\n",
      "215\n",
      "214\n",
      "213\n",
      "no words found\n",
      "212\n",
      "211\n",
      "210\n",
      "209\n",
      "208\n",
      "207\n",
      "206\n",
      "205\n",
      "204\n",
      "203\n",
      "202\n",
      "201\n",
      "200\n",
      "199\n",
      "198\n",
      "197\n",
      "196\n",
      "195\n",
      "no words found\n",
      "194\n",
      "no words found\n",
      "193\n",
      "192\n",
      "191\n",
      "190\n",
      "189\n",
      "188\n",
      "187\n",
      "186\n",
      "185\n",
      "184\n",
      "183\n",
      "182\n",
      "181\n",
      "180\n",
      "179\n",
      "178\n",
      "177\n",
      "176\n",
      "175\n",
      "174\n",
      "173\n",
      "172\n",
      "171\n",
      "no words found\n",
      "170\n",
      "169\n",
      "168\n",
      "167\n",
      "166\n",
      "165\n",
      "164\n",
      "163\n",
      "162\n",
      "161\n",
      "160\n",
      "159\n",
      "158\n",
      "157\n",
      "156\n",
      "155\n",
      "154\n",
      "153\n",
      "152\n",
      "151\n",
      "150\n",
      "149\n",
      "148\n",
      "147\n",
      "146\n",
      "145\n",
      "144\n",
      "143\n",
      "142\n",
      "141\n",
      "140\n",
      "139\n",
      "138\n",
      "137\n",
      "136\n",
      "135\n",
      "134\n",
      "133\n",
      "132\n",
      "131\n",
      "130\n",
      "129\n",
      "128\n",
      "127\n",
      "126\n",
      "125\n",
      "124\n",
      "123\n",
      "122\n",
      "121\n",
      "120\n",
      "119\n",
      "118\n",
      "117\n",
      "116\n",
      "115\n",
      "114\n",
      "113\n",
      "112\n",
      "111\n",
      "110\n",
      "109\n",
      "108\n",
      "107\n",
      "106\n",
      "105\n",
      "104\n",
      "103\n",
      "102\n",
      "101\n",
      "100\n",
      "99\n",
      "98\n",
      "97\n",
      "no words found\n",
      "96\n",
      "95\n",
      "94\n",
      "93\n",
      "92\n",
      "91\n",
      "90\n",
      "89\n",
      "88\n",
      "87\n",
      "86\n",
      "85\n",
      "84\n",
      "83\n",
      "82\n",
      "81\n",
      "80\n",
      "79\n",
      "78\n",
      "77\n",
      "76\n",
      "75\n",
      "74\n",
      "73\n",
      "72\n",
      "71\n",
      "70\n",
      "69\n",
      "68\n",
      "67\n",
      "66\n",
      "65\n",
      "64\n",
      "63\n",
      "62\n",
      "61\n",
      "60\n",
      "59\n",
      "58\n",
      "57\n",
      "56\n",
      "55\n",
      "54\n",
      "53\n",
      "52\n",
      "51\n",
      "50\n",
      "no words found\n",
      "49\n",
      "48\n",
      "47\n",
      "46\n",
      "45\n",
      "44\n",
      "43\n",
      "42\n",
      "41\n",
      "40\n",
      "39\n",
      "38\n",
      "37\n",
      "36\n",
      "35\n",
      "34\n",
      "33\n",
      "no words found\n",
      "32\n",
      "no words found\n",
      "31\n",
      "30\n",
      "29\n",
      "28\n",
      "27\n",
      "26\n",
      "25\n",
      "24\n",
      "23\n",
      "22\n",
      "no words found\n",
      "21\n",
      "20\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "no words found\n",
      "9\n",
      "8\n",
      "no words found\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for x in range(22, 31):\n",
    "    df = hit_api(x, x+1, 'Warren OR Elizabeth Warren', myString2)\n",
    "\n",
    "# collapse list on itself to build big df\n",
    "Cand_df = pd.concat(df)\n",
    "Cand_df = Cand_df.reset_index(drop=True)\n",
    "error_checks()\n",
    "\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36'}\n",
    "## Build counts as check on progress of loop. will count down Url left to hit\n",
    "counts=Cand_df['url'].shape[0]\n",
    "list_full_text=[]\n",
    "for link in Cand_df['url']:\n",
    "    counts-=1\n",
    "    print(counts)\n",
    "    html = requests.get(link,headers=headers).text\n",
    "    try: text = fulltext(html)\n",
    "    except: \n",
    "        print(\"no words found\")\n",
    "        text=\"no words found\"\n",
    "        list_full_text.append(text)\n",
    "        continue\n",
    "    list_full_text.append(text)\n",
    "Cand_df['full_art']=pd.Series(list_full_text)\n",
    "Cand_df.to_csv('data_csvs/data1'+str(time.time())+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape WAPO New York magazine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query will return: 29\n",
      "query will return: 26\n",
      "query will return: 29\n",
      "query will return: 26\n",
      "query will return: 21\n",
      "query will return: 23\n",
      "query will return: 20\n",
      "query will return: 19\n",
      "query will return: 370\n",
      "we should expect: 1039 articles\n",
      "we have: 545 articles\n",
      "494 results came into query that exceeded 100 hits in a day.\n",
      "we have 385 unique links\n",
      "we have duplciate shape df of: (160, 7) \n",
      "544\n",
      "543\n",
      "542\n",
      "541\n",
      "no words found\n",
      "540\n",
      "539\n",
      "538\n",
      "537\n",
      "536\n",
      "535\n",
      "534\n",
      "no words found\n",
      "533\n",
      "532\n",
      "531\n",
      "530\n",
      "529\n",
      "528\n",
      "527\n",
      "526\n",
      "525\n",
      "524\n",
      "523\n",
      "522\n",
      "521\n",
      "520\n",
      "519\n",
      "518\n",
      "no words found\n",
      "517\n",
      "516\n",
      "515\n",
      "514\n",
      "513\n",
      "no words found\n",
      "512\n",
      "511\n",
      "510\n",
      "509\n",
      "508\n",
      "507\n",
      "506\n",
      "no words found\n",
      "505\n",
      "504\n",
      "503\n",
      "502\n",
      "501\n",
      "500\n",
      "499\n",
      "498\n",
      "497\n",
      "496\n",
      "495\n",
      "494\n",
      "493\n",
      "492\n",
      "491\n",
      "490\n",
      "489\n",
      "488\n",
      "no words found\n",
      "487\n",
      "no words found\n",
      "486\n",
      "485\n",
      "484\n",
      "483\n",
      "482\n",
      "481\n",
      "480\n",
      "479\n",
      "478\n",
      "477\n",
      "476\n",
      "475\n",
      "474\n",
      "473\n",
      "472\n",
      "471\n",
      "470\n",
      "469\n",
      "468\n",
      "467\n",
      "466\n",
      "465\n",
      "464\n",
      "no words found\n",
      "463\n",
      "462\n",
      "461\n",
      "460\n",
      "459\n",
      "458\n",
      "457\n",
      "456\n",
      "455\n",
      "454\n",
      "453\n",
      "452\n",
      "451\n",
      "450\n",
      "449\n",
      "448\n",
      "447\n",
      "446\n",
      "445\n",
      "444\n",
      "443\n",
      "442\n",
      "441\n",
      "440\n",
      "439\n",
      "438\n",
      "437\n",
      "436\n",
      "435\n",
      "434\n",
      "433\n",
      "432\n",
      "431\n",
      "430\n",
      "429\n",
      "428\n",
      "427\n",
      "426\n",
      "425\n",
      "424\n",
      "423\n",
      "422\n",
      "421\n",
      "420\n",
      "419\n",
      "418\n",
      "417\n",
      "416\n",
      "415\n",
      "414\n",
      "413\n",
      "412\n",
      "411\n",
      "410\n",
      "409\n",
      "408\n",
      "407\n",
      "406\n",
      "405\n",
      "404\n",
      "403\n",
      "402\n",
      "401\n",
      "400\n",
      "399\n",
      "398\n",
      "397\n",
      "396\n",
      "395\n",
      "394\n",
      "393\n",
      "392\n",
      "391\n",
      "390\n",
      "no words found\n",
      "389\n",
      "388\n",
      "387\n",
      "386\n",
      "385\n",
      "384\n",
      "383\n",
      "382\n",
      "381\n",
      "380\n",
      "379\n",
      "378\n",
      "377\n",
      "376\n",
      "375\n",
      "374\n",
      "373\n",
      "372\n",
      "371\n",
      "370\n",
      "369\n",
      "368\n",
      "367\n",
      "366\n",
      "365\n",
      "364\n",
      "363\n",
      "362\n",
      "361\n",
      "360\n",
      "359\n",
      "358\n",
      "357\n",
      "356\n",
      "355\n",
      "354\n",
      "353\n",
      "352\n",
      "351\n",
      "350\n",
      "349\n",
      "348\n",
      "347\n",
      "346\n",
      "345\n",
      "344\n",
      "343\n",
      "no words found\n",
      "342\n",
      "341\n",
      "340\n",
      "339\n",
      "338\n",
      "337\n",
      "336\n",
      "335\n",
      "334\n",
      "333\n",
      "332\n",
      "331\n",
      "330\n",
      "329\n",
      "328\n",
      "327\n",
      "326\n",
      "no words found\n",
      "325\n",
      "no words found\n",
      "324\n",
      "323\n",
      "322\n",
      "321\n",
      "320\n",
      "319\n",
      "318\n",
      "317\n",
      "316\n",
      "315\n",
      "no words found\n",
      "314\n",
      "313\n",
      "312\n",
      "311\n",
      "310\n",
      "309\n",
      "308\n",
      "307\n",
      "306\n",
      "305\n",
      "304\n",
      "303\n",
      "no words found\n",
      "302\n",
      "301\n",
      "no words found\n",
      "300\n",
      "299\n",
      "298\n",
      "297\n",
      "296\n",
      "295\n",
      "294\n",
      "293\n",
      "292\n",
      "291\n",
      "290\n",
      "289\n",
      "288\n",
      "287\n",
      "286\n",
      "285\n",
      "284\n",
      "283\n",
      "282\n",
      "281\n",
      "280\n",
      "279\n",
      "278\n",
      "277\n",
      "276\n",
      "275\n",
      "274\n",
      "273\n",
      "272\n",
      "271\n",
      "270\n",
      "269\n",
      "268\n",
      "267\n",
      "266\n",
      "265\n",
      "264\n",
      "263\n",
      "262\n",
      "261\n",
      "260\n",
      "259\n",
      "258\n",
      "257\n",
      "256\n",
      "255\n",
      "254\n",
      "253\n",
      "252\n",
      "251\n",
      "250\n",
      "249\n",
      "248\n",
      "247\n",
      "246\n",
      "245\n",
      "244\n",
      "243\n",
      "242\n",
      "241\n",
      "240\n",
      "239\n",
      "238\n",
      "237\n",
      "236\n",
      "235\n",
      "234\n",
      "233\n",
      "232\n",
      "231\n",
      "230\n",
      "229\n",
      "228\n",
      "227\n",
      "226\n",
      "225\n",
      "224\n",
      "223\n",
      "222\n",
      "221\n",
      "220\n",
      "219\n",
      "218\n",
      "217\n",
      "216\n",
      "215\n",
      "214\n",
      "213\n",
      "212\n",
      "211\n",
      "210\n",
      "209\n",
      "208\n",
      "207\n",
      "206\n",
      "205\n",
      "204\n",
      "203\n",
      "202\n",
      "201\n",
      "200\n",
      "199\n",
      "198\n",
      "197\n",
      "196\n",
      "195\n",
      "194\n",
      "193\n",
      "192\n",
      "191\n",
      "190\n",
      "189\n",
      "188\n",
      "187\n",
      "186\n",
      "185\n",
      "184\n",
      "183\n",
      "182\n",
      "181\n",
      "180\n",
      "179\n",
      "178\n",
      "177\n",
      "176\n",
      "175\n",
      "174\n",
      "173\n",
      "172\n",
      "171\n",
      "170\n",
      "169\n",
      "168\n",
      "167\n",
      "166\n",
      "165\n",
      "164\n",
      "163\n",
      "162\n",
      "161\n",
      "160\n",
      "159\n",
      "158\n",
      "157\n",
      "156\n",
      "155\n",
      "154\n",
      "153\n",
      "152\n",
      "151\n",
      "150\n",
      "149\n",
      "148\n",
      "147\n",
      "146\n",
      "145\n",
      "144\n",
      "143\n",
      "142\n",
      "141\n",
      "140\n",
      "139\n",
      "138\n",
      "137\n",
      "136\n",
      "135\n",
      "134\n",
      "133\n",
      "132\n",
      "131\n",
      "130\n",
      "129\n",
      "128\n",
      "127\n",
      "126\n",
      "125\n",
      "124\n",
      "123\n",
      "122\n",
      "121\n",
      "120\n",
      "119\n",
      "118\n",
      "117\n",
      "116\n",
      "115\n",
      "114\n",
      "113\n",
      "112\n",
      "111\n",
      "110\n",
      "109\n",
      "108\n",
      "107\n",
      "106\n",
      "105\n",
      "104\n",
      "103\n",
      "102\n",
      "101\n",
      "100\n",
      "99\n",
      "98\n",
      "97\n",
      "96\n",
      "95\n",
      "94\n",
      "93\n",
      "92\n",
      "91\n",
      "90\n",
      "89\n",
      "88\n",
      "87\n",
      "86\n",
      "85\n",
      "84\n",
      "83\n",
      "82\n",
      "81\n",
      "80\n",
      "79\n",
      "78\n",
      "77\n",
      "76\n",
      "75\n",
      "74\n",
      "73\n",
      "72\n",
      "71\n",
      "70\n",
      "69\n",
      "68\n",
      "67\n",
      "66\n",
      "65\n",
      "64\n",
      "63\n",
      "62\n",
      "61\n",
      "60\n",
      "59\n",
      "58\n",
      "57\n",
      "56\n",
      "55\n",
      "54\n",
      "53\n",
      "52\n",
      "51\n",
      "50\n",
      "49\n",
      "48\n",
      "47\n",
      "46\n",
      "45\n",
      "44\n",
      "43\n",
      "42\n",
      "41\n",
      "40\n",
      "39\n",
      "38\n",
      "37\n",
      "36\n",
      "35\n",
      "34\n",
      "33\n",
      "32\n",
      "31\n",
      "30\n",
      "29\n",
      "28\n",
      "27\n",
      "26\n",
      "25\n",
      "24\n",
      "23\n",
      "22\n",
      "21\n",
      "20\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for x in range(22, 31):\n",
    "    df = hit_api(x, x+1, 'Biden OR Elizabeth Warren', myString)\n",
    "\n",
    "# collapse list on itself to build big df\n",
    "Cand_df = pd.concat(df)\n",
    "Cand_df = Cand_df.reset_index(drop=True)\n",
    "error_checks()\n",
    "\n",
    "\n",
    "## Build counts as check on progress of loop. will count down Url left to hit\n",
    "counts=Cand_df['url'].shape[0]\n",
    "list_full_text=[]\n",
    "for link in Cand_df['url']:\n",
    "    counts-=1\n",
    "    print(counts)\n",
    "    html = requests.get(link,headers=headers).text\n",
    "    try: text = fulltext(html)\n",
    "    except: \n",
    "        print(\"no words found\")\n",
    "        text=\"no words found\"\n",
    "        list_full_text.append(text)\n",
    "        continue\n",
    "    list_full_text.append(text)\n",
    "Cand_df['full_art']=pd.Series(list_full_text)\n",
    "Cand_df.to_csv('data_csvs/data1'+str(time.time())+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df=pd.read_csv('Vikas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'author', 'content', 'description',\n",
       "       'publishedAt', 'source', 'title', 'url', 'full_art'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       “Young people are constantly signaling what’s ...\n",
       "1       WASHINGTON — For months this spring and summer...\n",
       "2       WASHINGTON — President Trump pressed the Ukrai...\n",
       "3       WASHINGTON — President Trump on Saturday dismi...\n",
       "4       Though he has yet to call for impeachment proc...\n",
       "5       Why is this coming up now?\\r\\r\\n\\r\\r\\nAn intel...\n",
       "6       CEDAR RAPIDS, Iowa — Former Vice President Jos...\n",
       "7       “Some government lawyer would be nervous to do...\n",
       "8       Will this fine-tuning be enough in an agitated...\n",
       "9       President Trump in a July phone call repeatedl...\n",
       "10      Kamala Harris’s campaign says she is focusing ...\n",
       "11      President Trump pressed on with calls for an i...\n",
       "12      WASHINGTON — Everyone here is keyed up for the...\n",
       "13      To the Editor:\\r\\r\\n\\r\\r\\nRe “Claim on Trump I...\n",
       "14      WASHINGTON—Elizabeth Warren is building a broa...\n",
       "15      Presidents these days always seem to get worse...\n",
       "16      On Thursday, Mr. Atkinson appeared before a me...\n",
       "17      Mayor Pete Buttigieg of South Bend, Ind., plac...\n",
       "18      Mr. Schiff, speaking on CNN’s “State of the Un...\n",
       "19      A new poll from The Des Moines Register and CN...\n",
       "20      The story of Donald Trump’s phone call to Ukra...\n",
       "21      Democratic presidential candidates are present...\n",
       "22      Listen and subscribe to our podcast from your ...\n",
       "23      WASHINGTON — The last time he was accused of c...\n",
       "24      He is still doing some campaigning as it used ...\n",
       "25      WASHINGTON—For weeks, lawmakers of both partie...\n",
       "26      Nobody is arguing that the Bidens are in the s...\n",
       "27      KIEV, Ukraine — Senior Ukrainian officials sai...\n",
       "28      To the Editor:\\r\\r\\n\\r\\r\\nRe “Trump Admits He ...\n",
       "29      The prosecutor general, Viktor Shokin, was soo...\n",
       "                              ...                        \n",
       "2161    Former Vice President and 2020 candidate Joe B...\n",
       "2162    Washington (CNN) President Donald Trump has sp...\n",
       "2163    Joe Biden’s top political donors gathered for ...\n",
       "2164    During an appearance on Fox News Channel’s “Ju...\n",
       "2165    On Friday’s broadcast of HBO’s “Real Time,” ho...\n",
       "2166    Former Vice President Joe Biden’s son, Hunter ...\n",
       "2167    On Thursday’s broadcast of CNN’s town hall on ...\n",
       "2168    Sunday during an appearance on CNN’s “Newsroom...\n",
       "2169    \"Real Time\" host Bill Maher took aim at Democr...\n",
       "2170    Rep. Joe Kennedy III, D-Mass., announced Satur...\n",
       "2171    A Florida smoke shop owner was murdered during...\n",
       "2172    John Bolton had to know he was sending a messa...\n",
       "2173    The high-tax policy ideas of progressive Democ...\n",
       "2174    Facebook CEO Mark Zuckerberg committed to trea...\n",
       "2175    \"The Five\" discussed presidential candidate Jo...\n",
       "2176    Presidential hopeful Sen. Elizabeth Warren pro...\n",
       "2177    Democratic presidential candidate Sen. Elizabe...\n",
       "2178    Sen. Elizabeth Warren, D-Mass., said she is co...\n",
       "2179    Democratic presidential candidate Elizabeth Wa...\n",
       "2180    (CNN) Democratic Rep. Joe Kennedy III of Massa...\n",
       "2181    (CNN) House Speaker Nancy Pelosi slammed the T...\n",
       "2182    (CNN) Billionaire Robert Smith has made good o...\n",
       "2183    Rep. Joe Kennedy III (D-MA) formally announced...\n",
       "2184    00:00\\r\\r\\n\\r\\r\\nA SENIOR ADVISOR. SARAH, LET ...\n",
       "2185    (CNN) Rep. Alexandria Ocasio-Cortez never hid ...\n",
       "2186    Washington (CNN Business) Facebook ( FB ) CEO ...\n",
       "2187    Washington (CNN) Joe Biden has long wanted not...\n",
       "2188    New York (CNN Business) Is the market's love a...\n",
       "2189    Washington (CNN) Democratic Sen. Cory Booker, ...\n",
       "2190    (CNN) Joe Biden's presidential campaign says P...\n",
       "Name: full_art, Length: 2191, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df[\"full_art\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
